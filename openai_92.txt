Analysis and Study of Singles Badminton Player Actions Using Sports Videos
Understanding and analyzing badminton players’ actions from video is a multi-faceted research problem. This report breaks down the problem into four key components, each addressing a specific aspect: (1) object detection and tracking in badminton videos, (2) recognition of technical actions (strokes and movements), (3) inference of the tactical intent behind those actions, and (4) prediction of subsequent actions in a rally. For each component, we discuss the application context (coaching, analysis, or real-time systems), relevant technical frameworks (computer vision and deep learning methods), data considerations, modeling techniques, implementation best practices, evaluation metrics, and comparisons to related work. We also highlight strategies for dataset curation/annotation and improving generalization across different match scenarios.

Object Detection and Tracking within Badminton Videos
Context and Importance: In badminton video analysis, detecting and tracking key objects – mainly the players and the shuttlecock – is a foundational step. Accurate tracking enables downstream analysis such as shot classification, player movement metrics, or automated officiating (e.g., line calls). For coaching applications, player tracking can provide heatmaps of court coverage and footwork patterns, while shuttlecock tracking allows calculation of shot speed, trajectory, and placement. In real-time feedback systems or broadcasting, fast detection/tracking can power instant replays with augmented visuals (e.g. shuttle trajectory tracer or player run distance). This component is challenging because the shuttlecock is very small, moves extremely fast (often 300+ km/h in smashes), and can blur or occlude, whereas players may move rapidly and occasionally get occluded by the net or lighting variations.

Objects to Track: The primary objects are:

Shuttlecock: a fast-moving projectile with a tiny visual footprint. It can appear as a blur or even vanish in motion on standard frame-rate video. Tracking the shuttlecock provides shot trajectories and is crucial for identifying shot events (when a hit occurs, the shuttle direction changes).
Players: typically one player on each side in singles. Tracking players (via bounding boxes or pose keypoints) yields movement patterns, positions, and can feed tactical analysis (like how players position themselves). Additional elements can include the racket (to detect swings) or court lines (for coordinate calibration), but these are secondary.
Data Sources and Video Formats: Badminton match videos are commonly available from tournament broadcasts (e.g., BWF matches on YouTube). These usually have a single fixed camera angle from the back or side of the court, at 24–60 FPS, 720p or 1080p resolution. The background can vary: some venues have complex advertising boards or crowds in view, which can distract generic detectors. Training data for detection may require manual annotation of thousands of frames with shuttlecock and player positions. Some specialized datasets exist: for example, the Sports Ball Detection and Tracking (SBDT) dataset includes shuttlecock tracking instances, and the TrackNet authors introduced a dataset for badminton/tennis ball trajectories ([TrackNetV2: Efficient Shuttlecock Tracking Network | Papers With Code](https://paperswithcode.com/paper/tracknetv2-efficient-shuttlecock-tracking#:~:text=TrackNet%2C a deep learning network%2C,input image size and re)). If multiple camera views are available (as in advanced systems like Hawk-Eye used in professional tennis), 3D tracking is possible via triangulation; however, most research uses monocular 2D tracking from a single view, sometimes calibrating to court coordinates.

Technical Frameworks for Detection/Tracking: Modern approaches rely on deep learning:

Convolutional Neural Networks (CNNs) for Object Detection: Frameworks like YOLO (You Only Look Once), Faster R-CNN, or SSD can detect players and shuttlecocks in each frame. For player detection, general-purpose person detectors (trained on COCO or similar datasets) often work well, as players are relatively large and human-shaped. The shuttlecock, however, is not a common object in generic datasets, so a custom-trained detector is needed. Researchers have successfully trained YOLO models to detect shuttlecocks despite their small size ([Detecting the shuttlecock for a badminton robot: A YOLO based ...](https://www.sciencedirect.com/science/article/abs/pii/S0957417420306436#:~:text=,moves fast in complex)). One study on a badminton robot used a YOLO-based model specifically for shuttlecock detection, noting the challenge of motion blur and complex backgrounds ([Detecting the shuttlecock for a badminton robot: A YOLO based ...](https://www.sciencedirect.com/science/article/abs/pii/S0957417420306436#:~:text=
Specialized Small Object Trackers: A notable approach is TrackNet, a deep network designed for fast-moving tiny objects. TrackNet takes multiple consecutive frames as input (a short video clip) and outputs the position of the object, leveraging temporal cues to handle motion blur and brief occlusions ([TrackNetV2: Efficient Shuttlecock Tracking Network | Papers With Code](https://paperswithcode.com/paper/tracknetv2-efficient-shuttlecock-tracking#:~:text=TrackNet%2C a deep learning network%2C,input image size and re)). Originally introduced for tennis ball tracking, TrackNet has been adapted to badminton. It uses a CNN (VGG16 layers) followed by deconvolution layers to produce a heatmap of probable locations ([Enhancing Badminton Game Analysis: An Approach to Shot Refinement via a Fusion of Shuttlecock Tracking and Hit Detection from Monocular Camera](https://www.mdpi.com/1424-8220/24/13/4372#:~:text=TrackNet ,objects moving at high speed)). By sliding over time, it can trace the shuttlecock’s trajectory even when individual frame detections are uncertain. An improved version, TrackNet v2, achieved real-time performance (32 FPS vs 2.6 FPS in the original) by network optimizations, while maintaining high accuracy ([TrackNetV2: Efficient Shuttlecock Tracking Network | Papers With Code](https://paperswithcode.com/paper/tracknetv2-efficient-shuttlecock-tracking#::text=usage,Then%2C to improve the prediction)).
Multi-Object Tracking (MOT) algorithms: Once objects are detected per frame, their identities can be maintained over time using tracking algorithms. For players, this can be as simple as consistently assigning the left/right or near/far court player IDs (since in singles, they rarely switch sides during a rally except between games). Classic MOT methods like Kalman Filters with Hungarian algorithm for assignment or modern trackers like DeepSORT (which uses object appearance embeddings) can ensure each bounding box is labeled as “Player A” or “Player B” across frames. For the shuttlecock, the identity is singular (only one shuttle), so the main task is interpolation through missed detections.
Pose estimation: Instead of or in addition to bounding boxes, one can track players via their skeleton keypoints (e.g., using OpenPose or MediaPipe Pose). This yields detailed movement data (joint angles, etc.) which is useful for analyzing footwork and technique. However, pose estimation can struggle with the fast motions and sometimes lower resolution of limbs in full-court views. It can be combined with tracking to enforce temporal consistency in keypoints.
Challenges and Solutions: The shuttlecock is the hardest object to track. It might disappear from regular-frame videos during fast smashes. High-speed cameras (120 FPS or more) can alleviate this but are not always available. Some solutions:

Use motion cues: Background subtraction or frame differencing can highlight fast-moving objects. The 2017 study by Weeratunga et al. detected player movement by frame differencing (Application of Computer Vision and Vector Space Model for Tactical Movement Classification in Badminton,× 3 erosion and drawing)) ([Application of Computer Vision and Vector Space Model for Tactical Movement Classification in Badminton](https://openaccess.thecvf.com/content_cvpr_2017_workshops/w2/papers/Weeratunga_Application_of_Computer_CVPR_2017_paper.pdf#:~:text=Figure 1,the annotation method were experimentally)), which could also isolate the shuttlecock if it’s the only small moving object, but this is unreliable with camera movements or when the shuttle is static.
Trajectory filtering and physics: Given the shuttlecock follows a parabolic trajectory under gravity (albeit with drag, since it decelerates rapidly), one can apply smoothing and predictive filters. TrackNet-based systems apply post-processing to link detections into a smooth trajectory and fill gaps. For instance, TrackNet uses a trajectory smoothing algorithm that fits a quadratic curve through recent points to interpolate when a detection is missed ([Enhancing Badminton Game Analysis: An Approach to Shot Refinement via a Fusion of Shuttlecock Tracking and Hit Detection from Monocular Camera](https://www.mdpi.com/1424-8220/24/13/4372#:~:text=compensate for the missing value,59]. The algorithm is)). It also employs a “Direction Identification Method” to detect sudden direction changes, which correspond to shot events (racket hits) ([Enhancing Badminton Game Analysis: An Approach to Shot Refinement via a Fusion of Shuttlecock Tracking and Hit Detection from Monocular Camera](https://www.mdpi.com/1424-8220/24/13/4372#:~:text=TrackNet proposed the Direction Identification,to change its flight direction)).
Lighting and contrast: Shuttlecocks are usually white (or yellow) and the court is often green/blue – color filtering can be a quick pre-processing step to reduce false positives, but only as an adjunct to more robust methods.
Real-time considerations: For coaching tools giving instant feedback, algorithms must operate at or near video frame rate. Lightweight models or optimized versions (like TrackNetv2 or YOLOv8 on GPU) are needed. Running a full CNN on each frame might be heavy, so strategies like frame skipping (processing every nth frame) or region of interest tracking (focus search where shuttle is expected next based on physics) can help maintain speed.
Integration of Detection and Tracking: A promising strategy is multi-stage pipelines that combine detection and tracking outputs to improve each other:

Hsu et al. (2023) used TrackNet to get shuttle candidate positions and YOLOv7 to detect when a player is in a hitting posture, then fused these to pinpoint the exact hit moment and refine the shuttle trajectory ([Enhancing Badminton Game Analysis: An Approach to Shot Refinement via a Fusion of Shuttlecock Tracking and Hit Detection from Monocular Camera](https://www.mdpi.com/1424-8220/24/13/4372#:~:text=Extracting the flight trajectory of,Our proposed method)) ([Enhancing Badminton Game Analysis: An Approach to Shot Refinement via a Fusion of Shuttlecock Tracking and Hit Detection from Monocular Camera](https://www.mdpi.com/1424-8220/24/13/4372#:~:text=model is used to identify,1)). This fusion reduced false positives and raised accuracy of detecting shot events to 89.7% (with 91.3% recall) – a significant improvement over using TrackNet alone (which had high recall but only ~58.8% precision) ([Enhancing Badminton Game Analysis: An Approach to Shot Refinement via a Fusion of Shuttlecock Tracking and Hit Detection from Monocular Camera](https://www.mdpi.com/1424-8220/24/13/4372#::text=model
For player tracking, one can use detection in key frames and optical flow or feature tracking in intermediate frames to get smoother trajectories at lower cost, correcting the detection periodically.
Performance Metrics: Evaluating detection and tracking in badminton can use several metrics:

Detection metrics: If treating it as object detection in each frame, Precision, Recall, and mAP (mean Average Precision) at a certain IoU threshold are common. For shuttlecock detection, IoU (intersection-over-union) may be less meaningful (a small 5-pixel error is huge for shuttlecock). Instead, an absolute pixel distance error or success rate within X pixels may be used.
Tracking metrics: In multi-object tracking, MOTA (Multiple Object Tracking Accuracy) and MOTP (Precision) are used. Here, since we have at most 3 objects (shuttle, player1, player2), one can simply report the percentage of frames each object is correctly tracked (within a tolerance). For shuttle trajectory, metrics like average position error per frame or the percentage of complete trajectories correctly reconstructed are relevant. Some works use frame recall (the fraction of frames the shuttle is successfully detected). For example, TrackNet reported 94% frame recall but needed improvements in precision ([Enhancing Badminton Game Analysis: An Approach to Shot Refinement via a Fusion of Shuttlecock Tracking and Hit Detection from Monocular Camera](https://www.mdpi.com/1424-8220/24/13/4372#::text=model is used to identify,1)).
Event detection metrics: If the goal is to detect the moment of a shot (racket-shuttle contact), one can measure hit detection accuracy (did we correctly identify the frame of each actual hit). Hsu et al. measure this as precision/recall of shot event identification, achieving about 90% F1-score ([Enhancing Badminton Game Analysis: An Approach to Shot Refinement via a Fusion of Shuttlecock Tracking and Hit Detection from Monocular Camera](https://www.mdpi.com/1424-8220/24/13/4372#:~:text=model is used to identify,1)).
Latency and speed: Especially for real-time systems, measure the processing frame rate or latency on given hardware.
Related Research: Similar problems have been tackled in other racket sports. In tennis, commercial systems like Hawk-Eye use multiple high-speed cameras to triangulate the 3D position of the ball for line calls and player tracking; however, in research, monocular methods like TrackNet have shown that deep learning can track a tennis ball or shuttle from a single view with good accuracy ([TrackNetV2: Efficient Shuttlecock Tracking Network | Papers With Code](https://paperswithcode.com/paper/tracknetv2-efficient-shuttlecock-tracking#:~:text=TrackNet%2C a deep learning network%2C,input image size and re)). Comparing sports, badminton’s shuttlecock is lighter and decelerates more abruptly than a tennis ball, making purely physics-based prediction less reliable – hence the reliance on learning-based trackers. In soccer, ball tracking is also challenging (small fast object with motion blur); approaches from soccer (like detecting ball candidates and using optical flow) share similarities. Our use-case is most akin to tennis and volleyball (tracking the ball) and to motion capture (tracking players). Weeratunga et al. (2017) demonstrated a classical vision approach for player tracking in badminton: background subtraction, morphological filtering, and manual calibration to map player positions onto divided court zones (Application of Computer Vision and Vector Space Model for Tactical Movement Classification in Badminton,× 3 erosion and drawing)) ([Application of Computer Vision and Vector Space Model for Tactical Movement Classification in Badminton](https://openaccess.thecvf.com/content_cvpr_2017_workshops/w2/papers/Weeratunga_Application_of_Computer_CVPR_2017_paper.pdf#:~:text=2,the player position is first)). While less automated (they manually calibrated court corners and corrected tracking), this provided data for tactical analysis. Today, deep learning significantly improves the robustness of detection and tracking; for instance, even occluded or blurred shuttlecock positions can be inferred by CNNs, and players can be tracked through quick movements by combining pose estimation and detection.

Best Practices and Recommendations: In implementing detection/tracking for badminton:

Camera calibration: If possible, calibrate the video to known court dimensions. This allows converting pixel coordinates to real-world distances (useful for measuring shot distances or speed) and normalizing across different camera setups. It also helps filter impossible locations (e.g., shuttle can only move within the court’s airspace).
Data augmentation: To improve generalization, augment training images with variations in brightness, motion blur, rotation, and background noise. This helps the detector cope with different arenas and video quality. For example, adding synthetic motion blur in random directions can teach the model to recognize stretched, blurred shuttlecock images.
Annotation strategy: For building training data, one strategy is to use an initial tracker (like TrackNet or simple frame differencing) to generate candidate positions, then have human annotators correct them. This semi-automated labeling speeds up the creation of a large annotated dataset of shuttle trajectories and player bounding boxes. Ensuring a diverse set of videos (different tournaments, camera angles, player clothing colors, etc.) in the training set will make the model more robust.
Combined models: Consider joint detection and tracking frameworks. Recently, Transformers have been used in vision (e.g., DETR – Detection Transformer) for end-to-end object detection which also can incorporate temporal information. A future direction could be a unified model that takes a sequence of frames and outputs the trajectories of players and shuttle directly, possibly leveraging attention to link positions over time. This could simplify pipelines and potentially yield better global consistency.
Edge Cases: Account for cases like shuttlecock leaving the frame (high lifts might go out of top frame) – the system should handle re-entry smoothly. Also, when rallies end, trackers should reset identities for the next rally (to avoid confusion if players switch sides between games).
Integration with domain knowledge: Use badminton-specific knowledge: for instance, there can only be at most one shuttlecock in play; players stay on their side of the net; a shuttle’s flight between hits is strictly a free-fall trajectory. These constraints can be encoded to reject spurious detections (e.g., ignore a “shuttle” detection far away from the trajectory path, or a “player” detection on the wrong side of the net).
In summary, robust object detection and tracking in badminton videos is achievable by combining deep learning detectors (like YOLO for players, TrackNet for the shuttlecock) with clever tracking algorithms and domain-specific filtering. High accuracy in this component (as evidenced by 90% F1 in shuttle hit detection using fused methods ([Enhancing Badminton Game Analysis: An Approach to Shot Refinement via a Fusion of Shuttlecock Tracking and Hit Detection from Monocular Camera](https://www.mdpi.com/1424-8220/24/13/4372#::text=model is used to identify,1))) lays the groundwork for the subsequent analysis of strokes and tactics.

Recognition of Technical Actions Performed by Singles Players
What Are “Technical Actions”? This refers to identifying the specific badminton skills or moves a player executes. In singles, the primary technical actions are the strokes (shots played with the racket) – for example: serve, clear (lob), drop shot, smash, drive, net shot, lift, etc. Additionally, one can include footwork and body movements (jumps, lunges, defensive stance) as part of technical actions, since badminton performance is a combination of stroke technique and movement technique. In the context of video analysis, however, most research focuses on classifying the stroke type from video footage. Fine-grained action recognition in badminton is challenging because many shots can look similar in posture but differ in outcome (e.g., a stick-smash vs. a punch-clear). Nevertheless, recognizing these actions is vital for coaching feedback (e.g., how often a player uses a smash vs. drop, or whether their backhand clear is technically correct), match analysis (identifying what shots were played in a rally), and annotation of videos for highlight reels or statistics.

Application Context: A coaching application might automatically log each shot type a player uses during practice matches and assess their technique (perhaps even scoring the quality of execution, though that veers into “action quality assessment”). In sports science, identifying strokes can help correlate certain techniques with rally outcomes or injury risks. Real-time systems could display the recognized shot on screen for viewers (“Player A performs a smash”). Also, from an academic perspective, this is a fine-grained action recognition problem that pushes the limits of video understanding – differentiating between, say, a fast drop shot and a slow drive requires subtle temporal and spatial reasoning.

Data and Annotation: To train models to recognize shot types, you need video segments labeled by the type of stroke. This usually means annotating the start and end of each stroke (or at least the moment of contact) and giving it a label (like “smash” or “clear”). Annotating technical actions can be labor-intensive and often requires badminton knowledge. Datasets such as the Badminton Activity Recognition (BAR) dataset have compiled clips of various strokes – BAR contains 12 commonly played strokes with associated footwork, contributed by University of Maryland researchers ([Badminton Activity Recognition (BAR) | IEEE DataPort](https://ieee-dataport.org/open-access/badminton-activity-recognition-bar#:~:text=The Badminton Activity Recognition ,capture the associated leg movements)). More recently, the VideoBadminton dataset introduced in 2024 provides a wealth of labeled badminton action clips, with a fine-grained taxonomy of 17 stroke types defined according to Badminton World Federation standards ([VideoBadminton: A Video Dataset for Badminton Action Recognition](https://arxiv.org/html/2403.12385v1#:~:text=”Short Serve” ,front of the service court)) (VideoBadminton: A Video Dataset for Badminton Action Recognition).

Modeling Techniques: Action recognition in sports videos can leverage several approaches:

Convolutional Neural Networks on Video: Classic approach is to use 2D CNNs on individual frames combined with a temporal model. For example, one might use a pretrained CNN (like ResNet or Inception) to extract frame features, then feed the sequence of features into an LSTM (Long Short-Term Memory) network or a Temporal Convolution to classify the sequence. This was a common approach in early deep learning for video. Alternatively, 3D CNNs (e.g., C3D, I3D (Inflated 3D ConvNet)) process a stack of frames (a short video snippet) in one go, learning spatiotemporal filters.
Two-Stream Networks: Because motion is important for distinguishing actions, the two-stream paradigm (Simonyan & Zisserman, 2014) processes RGB frames and optical flow separately through CNNs and then fuses the results. For badminton, the motion stream (optical flow) can help highlight the racket swing direction and shuttle trajectory – cues that differentiate a clear (upward motion) from a smash (downward motion), for example.
Transformers and Attention: More recently, Transformer-based architectures like TimeSformer, Video Swin Transformer, or hybrid CNN-Transformers have shown strong performance on action recognition. These models apply self-attention across space and time to learn the sequence of motions. Transformers can capture long-range dependencies (e.g., the preparation steps leading to a stroke). The VideoBadminton benchmark evaluated such models and found that a SlowFast CNN and a Swin Transformer achieved top-1 accuracies above 80% on their badminton action set (VideoBadminton: A Video Dataset for Badminton Action Recognition 79.53,69.93)) (VideoBadminton: A Video Dataset for Badminton Action Recognition 73.18,69.93)). Transformers may need larger datasets to generalize well – in fine-grained tasks, combining them with domain-specific features (like pose) can help.
Pose/Skeleton-based Recognition: Instead of raw pixels, one can feed the model a sequence of human pose keypoints (coordinates of joints like shoulders, elbows, wrists, etc.). This abstracts away appearance and focuses on motion dynamics. Graph neural networks such as ST-GCN (Spatial Temporal Graph Convolutional Network) treat the human body as a graph and model the joint movements to classify actions. In badminton, a skeleton-based model can pick up on the arm swing pattern and footwork without being distracted by jersey color or background. In experiments, skeleton-based models have been competitive: ST-GCN and a Pose-based C3D attained around 74–80% accuracy on badminton action classification, comparable to vision-based models (VideoBadminton: A Video Dataset for Badminton Action Recognition) (VideoBadminton: A Video Dataset for Badminton Action Recognition 73.18,69.93)). A combination of pose and raw video (multi-modal fusion) often gives the best of both worlds – leveraging pose for body movement and raw video for context like shuttle movement or precise contact timing.
Hybrid and Hierarchical Approaches: Some research suggests breaking actions into phases – e.g., preparation, hit, follow-through – especially in sports like badminton where each stroke has a distinct phase structure. A hybrid approach might first detect the key moment (impact with the shuttle) and then classify the action based on motion before and after that point. Classical machine learning can also play a role; for instance, features like racket swing speed (from optical flow) or shuttle trajectory angle (from tracking data) could feed into a classifier. Rule-based classification can complement ML: e.g., if shuttle trajectory is nearly horizontal and fast, it might be classified as a drive ([Enhancing Badminton Game Analysis: An Approach to Shot Refinement via a Fusion of Shuttlecock Tracking and Hit Detection from Monocular Camera](https://www.mdpi.com/1424-8220/24/13/4372#:~:text=An advantage of recognizing the,shot types is closely related)). In practice, pure deep learning tends to outperform handcrafted rules, but combining learned features with shuttle trajectory analysis can refine results ([Enhancing Badminton Game Analysis: An Approach to Shot Refinement via a Fusion of Shuttlecock Tracking and Hit Detection from Monocular Camera](https://www.mdpi.com/1424-8220/24/13/4372#:~:text=accuracy of shot type classification,validity of the proposed method)) ([Enhancing Badminton Game Analysis: An Approach to Shot Refinement via a Fusion of Shuttlecock Tracking and Hit Detection from Monocular Camera](https://www.mdpi.com/1424-8220/24/13/4372#:~:text=An
Implementation Frameworks: To implement these models, researchers use deep learning libraries such as PyTorch or TensorFlow/Keras. There are also specialized toolkits; for example, OpenMMLab’s MMAction2 is a framework that provides implementations of many action recognition models (TSN, SlowFast, PoseC3D, etc.) and was used to benchmark models on the VideoBadminton dataset ([VideoBadminton: A Video Dataset for Badminton Action Recognition](https://arxiv.org/html/2403.12385v1#:~:text=Appendix B The configuration settings,for the models trained)). For real-time applications, one might choose a lighter model (e.g., a smaller CNN or a pruned network) to achieve inference at, say, 30 FPS on a GPU. Another approach for efficiency is to run detection/tracking first – locate the region of the player and shuttle – then run the action classifier only on a cropped region or a resampled shorter clip around each hit event (instead of on the entire continuous video). This event-driven processing mirrors how humans analyze a rally: focusing on moments of shuttle contact.

Key Challenges: Recognizing fine-grained actions in badminton has unique challenges:

Subtle Visual Differences: Many shots share similar arm motions. A smash vs. a punch clear might only differ in racket angle and shuttle trajectory, which are hard to see from a single-view video. High-speed or high-resolution video might be needed to catch subtle differences in follow-through or shuttle speed. Models need to capture these subtleties – for example, by paying attention to the shuttle’s flight (if visible) or the player’s body posture (a smash often involves a jump or full rotation, whereas a clear might be played more flat-footed when under pressure).
Variety of Styles: Different players have different techniques (e.g., some have a more pronounced jump smash, others a stick smash). The model must generalize across players. Using player skeleton data helps normalize differences in appearance, but differences in execution speed or flourish still exist. This is where having player-diverse training data and possibly including player identity as an input (to allow the model to learn person-specific biases, as in the prediction component) can help.
Ambiguous Labels: Sometimes the line between actions is blurry. Is a fast downward shot from mid-court a “smash” or a “half-smash” or a “drive”? Even experts might disagree on labeling certain borderline cases. For modeling, it’s important to have clear definitions for annotators. One may choose a hierarchical approach (e.g., first classify into broad categories like clear vs. drop vs. smash, then into sub-categories like smash vs. half-smash). The VideoBadminton dataset’s fine classes ([VideoBadminton: A Video Dataset for Badminton Action Recognition](https://arxiv.org/html/2403.12385v1#:~:text=”Short Serve” ,front of the service court)) (VideoBadminton: A Video Dataset for Badminton Action Recognition)
Temporal Boundaries: Deciding the segment of video that constitutes the action – do we include the entire footwork leading up to it or just the immediate stroke? Many approaches center a short clip (1–2 seconds) around the hit moment for classification. Consistency in how segments are extracted during training and evaluation is crucial.
Performance Metrics: For action recognition models, the typical metrics are classification metrics:

Accuracy: The proportion of correctly classified action instances. Given multiple classes, we often use Top-1 accuracy (model’s top prediction is correct) and sometimes Top-5 accuracy (correct label is among the model’s top 5 guesses) for a more forgiving measure ([VideoBadminton: A Video Dataset for Badminton Action Recognition](https://arxiv.org/html/2403.12385v1#:~:text=incorporates Top,more comprehensive comparison across models)) ([VideoBadminton: A Video Dataset for Badminton Action Recognition](https://arxiv.org/html/2403.12385v1#:~:text=Top,array of potential correct predictions)). In fine-grained tasks, top-5 accuracy can be significantly higher than top-1, indicating the model often has the right answer in its shortlist but confuses between similar actions.
Mean per-class accuracy: To ensure performance isn’t skewed by more frequent classes, the average of accuracies for each class is reported ([VideoBadminton: A Video Dataset for Badminton Action Recognition](https://arxiv.org/html/2403.12385v1#:~:text=match at L752 Mean Class,ensures a uniform evaluation standard)). This is important if, say, “clears” are very common in the dataset but “drive shots” are rare – a model could get high overall accuracy by just guessing clear often. Mean class accuracy weighs each class equally.
Precision, Recall, F1: If actions are considered events in time, one might consider precision and recall in detecting them (but since we assume segments are pre-labeled, this is more for event detection evaluation). For classification, precision/recall per class can highlight, for example, that the model often confuses net shots with drops (lower precision for those classes).
Confusion Matrix: This is a useful tool to diagnose which actions are commonly mixed up. It might show, for instance, that backhand clears are often misclassified as drives due to similar arm motion. Such insights can drive improvements (maybe adding specific features or data for those confusions).
State-of-the-art models on a comprehensive dataset can exceed 80% top-1 accuracy for badminton stroke classification (VideoBadminton: A Video Dataset for Badminton Action Recognition 79.53,69.93)) (VideoBadminton: A Video Dataset for Badminton Action Recognition 73.18,69.93)), but performance greatly depends on the granularity of classes. When fine distinctions are required (like distinguishing 17 different shots), even advanced models may drop to lower accuracy (e.g., some models got only 20% on fine classes in initial VideoBadminton experiments ([VideoBadminton: A Video Dataset for Badminton Action Recognition](https://arxiv.org/html/2403.12385v1#::text=R(2%2B1)D(2018)

Related Work and Comparison: Sports action recognition has been studied in tennis (classifying forehand, backhand, serve), in golf (swing analysis), and even in multi-sport datasets. Badminton has its specific datasets as mentioned. A 2020 study by Shao et al. applied deep CNNs (AlexNet, GoogLeNet) on badminton action images to distinguish a few stroke types, achieving promising results for broad classes ([Optimizing Badminton Action Recognition with Deep Learning and ...](https://ieeexplore.ieee.org/document/10256460/#:~:text=,to recognize different badminton actions)). More advanced techniques now incorporate temporal modeling. Notably, the work by Hsu et al. (2023) showed that using the shuttlecock’s flight trajectory can help classify shot types ([Enhancing Badminton Game Analysis: An Approach to Shot Refinement via a Fusion of Shuttlecock Tracking and Hit Detection from Monocular Camera](https://www.mdpi.com/1424-8220/24/13/4372#:~:text=An advantage of recognizing the,shot types is closely related)). By tracking the shuttle and analyzing features like trajectory arc and speed, they could infer whether a shot was, say, a clear (high arc) versus a drive (flat trajectory). They achieved shot-type classification accuracies around 72% under certain conditions, outperforming a baseline TrackNet-only approach ([Enhancing Badminton Game Analysis: An Approach to Shot Refinement via a Fusion of Shuttlecock Tracking and Hit Detection from Monocular Camera](https://www.mdpi.com/1424-8220/24/13/4372#:~:text=achieves an accuracy of 89.7,validity of the proposed method)) ([Enhancing Badminton Game Analysis: An Approach to Shot Refinement via a Fusion of Shuttlecock Tracking and Hit Detection from Monocular Camera](https://www.mdpi.com/1424-8220/24/13/4372#:~:text=videos,to those of TrackNet%2C demonstrating)). This indicates that combining trajectory data with visual data improves recognition. Another angle is using audio, since the sound of a smash versus a drop can differ, but in noisy arenas that’s less reliable and not widely used yet.

Best Practices: To optimize technical action recognition:

Segmentation of actions: It’s crucial to isolate each action. One should use the results of the detection/tracking module (especially shuttlecock tracking) to segment the video into rallies and individual shots. For example, detect the moment of shuttle contact (hit) via shuttle trajectory change ([Enhancing Badminton Game Analysis: An Approach to Shot Refinement via a Fusion of Shuttlecock Tracking and Hit Detection from Monocular Camera](https://www.mdpi.com/1424-8220/24/13/4372#:~:text=TrackNet proposed the Direction Identification,to change its flight direction)), then take frames around that as the window for classification. This ensures the model focuses on the relevant part of the video for each action.
Transfer learning: Leverage models pre-trained on large action datasets (like Kinetics or HMDB) and fine-tune them on badminton data ([VideoBadminton: A Video Dataset for Badminton Action Recognition](https://arxiv.org/html/2403.12385v1#:~:text=on well,this dataset%2C this study aims)) ([VideoBadminton: A Video Dataset for Badminton Action Recognition](https://arxiv.org/html/2403.12385v1#:~:text=Alongside the evolution of video,have set new standards)). Fine-grained actions benefit from starting with a network that already understands general motion. The VideoBadminton paper emphasizes transfer learning and careful fine-tuning to adapt models to the nuances of badminton ([VideoBadminton: A Video Dataset for Badminton Action Recognition](https://arxiv.org/html/2403.12385v1#:~:text=match at L139 VideoBadminton dataset%2C,particularly in the sports domain)) ([VideoBadminton: A Video Dataset for Badminton Action Recognition](https://arxiv.org/html/2403.12385v1#:~:text=TimeSformer%2C Swim%2C MViT,perspectives specific to badminton games)).
Multimodal inputs: Combine RGB, optical flow, and pose. Each adds complementary information. For instance, a model could have one branch analyzing the player’s skeletal motion (to identify swing type) and another branch focusing on the shuttle’s motion in the video (to see outcome). Fusing these at a late stage (decision-level) or mid-stage (feature-level) often yields improvements.
Augmentation and diversity: Augment the training clips by mirroring (flipping left-right, which effectively swaps forehand/backhand and simulates opposite court view), changing playback speed slightly (to simulate different tempos), etc. Ensure the model sees both forehand and backhand variants of shots. If all your smash examples are forehand, the model might not recognize a backhand smash by another player.
Evaluation with context: Sometimes it’s useful to not only evaluate per-shot classification, but also how it performs in a full match scenario. Does the model maintain accuracy when processing continuous video of a match? This tests its ability to detect when an action is happening and classify it correctly. Also, evaluate both in controlled settings (e.g., training footage with clear view) and in broadcast footage (with possibly occlusions or camera panning).
Incremental improvement and expert feedback: Because this is for sports, having a coach or player review the model’s output can identify what mistakes are critical. For example, mislabeling a “clear” as a “lift” might be minor, but mislabeling a “smash” as a “clear” is a bigger issue in analyzing aggressiveness. Tuning the model (or the label taxonomy) to what is practically important ensures the analysis tool is useful.
Recognizing technical actions turns raw video into a symbolic sequence of events (e.g., Rally: “serve, clear, drop, lift, smash…”), which is invaluable for higher-level tactical analysis. With modern deep learning and sufficient training data, automated stroke classification is becoming feasible, moving from early results of 60% accuracy to more robust systems above 80% for many classes ([VideoBadminton: A Video Dataset for Badminton Action Recognition](https://arxiv.org/html/2403.12385v1#::text=R(2%2B1)D(2018) 79.53,69.93)) (VideoBadminton: A Video Dataset for Badminton Action Recognition 73.18,69.93)). The inclusion of domain-specific features like shuttle trajectory and pose data is a key trend to improve accuracy and generalization.

Recognition of Tactical Intent behind Singles Players’ Actions
Defining Tactical Intent: Tactical intent refers to the underlying strategy or purpose behind a player’s choice of action. In badminton singles, tactics revolve around how a player uses strokes to create advantages – for example, trying to move the opponent out of position, forcing a weak return, or conserving energy during a rally. Recognizing tactical intent means interpreting why a particular shot was played, not just what shot it was. This is a higher-level semantic understanding that often depends on the context of the rally, the positions of both players, and the sequence of shots. Examples of tactical intents in singles might include:

Offensive intent: e.g., a player smashes to try to win the point or pressure the opponent into a poor return. A fast drop shot might also be offensive if used to catch the opponent off guard.
Defensive intent: e.g., a player under pressure plays a high clear to reset the rally and gain time to recover position. Lifts from the net when forced by opponent’s drop are defensive.
Setup or Rally-building intent: using shots to set up a favorable situation later in the rally, rather than immediately win the point. For instance, a player might hit to the opponent’s backhand corner repeatedly (a tactical pattern) to elicit a weak backhand return eventually.
Deceptive or surprise intent: e.g., a player shows body language of a smash but then plays a soft drop – the intent is to wrong-foot the opponent.
Positional tactics: like aiming smashes at the opponent’s body (to jam them), or hitting to the four corners in succession to stretch the opponent’s movement.
These intents are not directly observable like a stroke type; they must be inferred from context. One approach is to classify tactical states of the rally: for example, label each shot as “attack”, “defend”, or “neutral”. Another approach is to identify known tactical patterns or strategies (e.g., “clear-and-drop” strategy: a player clears high and when the opponent returns a drop, the player is ready to pounce a net kill – this 1-2 pattern indicates an aggressive tactical play).

Application Context: For coaches and analysts, understanding tactics is the ultimate goal: beyond what techniques were used, they ask why did the player choose that shot and what was the intended effect? A system that recognizes tactical intent can provide insights like “Player A is playing very defensively, mostly clearing to the back” or “Player B often uses a smash-followed-by-net-rush tactic when the opponent’s lift is short.” In match preparation, a player could study an opponent’s common tactics (e.g., does the opponent have a tendency to play cross-court drop shots to end long rallies?). An academic interest is modeling decision-making in sport – tactical recognition is akin to understanding plans or policies in sequential decision processes. In real-time broadcast, it’s challenging to fully automate, but a simplified version might be annotating rallies as “defensive rally” vs “attacking rally” or highlighting particularly tactical moves (like a deceptive shot).

Data Requirements: Tactical intent is harder to label than strokes. It often requires expert annotation, where a coach or experienced analyst watches a rally and labels either each shot or the whole rally with tactical descriptors. One could derive some labels from outcome (e.g., any shot that immediately wins the point could be labeled “winning shot / attacking”), but many tactical shots don’t win the point outright. Some studies have defined tactical categories by partitioning the court and analyzing movement patterns. For instance, Weeratunga et al. defined ten tactical movement groups based on where players hit and moved (T1–T10 representing movement from center to various regions) ([Application of Computer Vision and Vector Space Model for Tactical Movement Classification in Badminton](https://openaccess.thecvf.com/content_cvpr_2017_workshops/w2/papers/Weeratunga_Application_of_Computer_CVPR_2017_paper.pdf#:~:text=2,two groups along)). Those groups can be seen as tactics like “moving opponent corner-to-corner” or “playing straight clears”. Domain experts were involved in naming these groups ([Application of Computer Vision and Vector Space Model for Tactical Movement Classification in Badminton](https://openaccess.thecvf.com/content_cvpr_2017_workshops/w2/papers/Weeratunga_Application_of_Computer_CVPR_2017_paper.pdf#:~:text=2

Features and Modeling Approaches:

Sequential Pattern Recognition: Tactics manifest over a sequence of shots. Thus, the input to a tactical intent recognizer could be the sequence of recent strokes and their outcomes, as well as player positions. One could represent a rally as a sequence of symbols (e.g., A:clear, B:drop, A:net shot, B:lift, …) and try to classify sequences or subsequences. Classical methods include using Hidden Markov Models (HMMs) or sequence clustering to identify common sequences. Frequent sequence mining can find patterns that occur often in winning rallies vs losing rallies.
Court Position and Trajectory Analysis: Where the shuttle lands or where the player moves are strong indicators of tactic. If a player consistently hits to the back corners, the intent might be to keep the opponent in the rear court (a common defensive tactic to buy time, or an offensive one if opponent is weaker in backcourt). Dividing the court into regions (as in a 3x3 grid per side ([Application of Computer Vision and Vector Space Model for Tactical Movement Classification in Badminton](https://openaccess.thecvf.com/content_cvpr_2017_workshops/w2/papers/Weeratunga_Application_of_Computer_CVPR_2017_paper.pdf#:~:text=2,the player position is first))) and tracking transitions can quantify tactics. For example, “opponent was in back-left, player hits to front-right” could be seen as a diagonal attacking play. Weeratunga’s work essentially encoded player movement trajectories through these court cells and grouped them into tactical categories ([Application of Computer Vision and Vector Space Model for Tactical Movement Classification in Badminton](https://openaccess.thecvf.com/content_cvpr_2017_workshops/w2/papers/Weeratunga_Application_of_Computer_CVPR_2017_paper.pdf#:~:text=frequent trajectories to ten tactical,results used to visualise meaningful)). They then classified new trajectories into these categories using a k-Nearest Neighbor algorithm with a similarity measure on trajectories ([Application of Computer Vision and Vector Space Model for Tactical Movement Classification in Badminton](https://openaccess.thecvf.com/content_cvpr_2017_workshops/w2/papers/Weeratunga_Application_of_Computer_CVPR_2017_paper.pdf#:~:text=2
Machine Learning Classification: If we define tactical intent labels for each shot or rally (e.g., label each shot as “attack” or “defend”), we can train classifiers on features of that shot. Features might include: the shot type (from the previous component), the players’ positions and momentum (from tracking data), the rally stage (early rally vs late rally), and the opponent’s state (out of position or not). A simple example: a decision tree might learn that “if player is off-balance and hits a high clear, label it Defensive; if player jumps and smashes, label it Offensive.” More complex, a deep model like a bi-directional LSTM or Transformer could take the entire sequence of shots in the rally and output a sequence of labels indicating tactical intent for each shot or a single label for the overall tactic of the rally. The attention mechanism in transformers could help highlight which shots in the sequence define the tactic (similar to how some models infer key actions that decide a rally ([Exploring the Long Short-Term Dependencies to Infer Shot Influence ...](https://ieeexplore.ieee.org/document/9679184/#:~:text=Exploring the Long Short,essential for badminton experts))).
Multi-Agent Consideration: Tactics involve the interplay of two players. A model might need to consider both sides’ actions. One approach is a turn-based analysis, where features describe the state when a player is about to hit: e.g., “player A is in rear court, player B in front court, shuttle is high to A’s backhand – A’s next shot likely has defensive intent (e.g., clear)”. Incorporating both players’ positions and the shuttle state is crucial. This can be done by constructing state vectors for each shot (like [attacker_position, defender_position, shuttle_position, previous_shot_type]) and feeding that into a classifier.
Rule-based heuristics with learning: Some systems might incorporate explicit rules given by coaches. For example, a rule might say “if a player’s shot makes the opponent move more than X meters, that shot had offensive intent” – such rules can be combined with learning models to refine or validate tactical labeling.
Challenges:

Subjectivity: Tactical intent can be subjective. Some shots have obvious intent (a smash is nearly always attacking), but others depend on context (a clear could be attacking if the opponent is out of position, or defensive if the player themself was out of position). It might require looking at the subsequent outcome: if a clear forces a weak return, it was a successful attacking clear; if it simply relieved pressure, it was defensive.
Temporal scope: Should tactical intent be assigned per shot or per rally? Possibly both – micro-intents per shot and an overall tactic for the rally. For automatic recognition, per-shot intent might be easier to align with features, but overall strategy might emerge only when looking at several shots together (e.g., “Player A is engaging in a net duel tactic this rally” which is a series of net shots back and forth).
Data scarcity for labels: Unlike strokes which can be labeled from video relatively objectively, tactics often require expert annotation, which is scarce. Semi-supervised approaches (clustering patterns and then labeling clusters with meaningful names) can mitigate this, as done in some research ([Application of Computer Vision and Vector Space Model for Tactical Movement Classification in Badminton](https://openaccess.thecvf.com/content_cvpr_2017_workshops/w2/papers/Weeratunga_Application_of_Computer_CVPR_2017_paper.pdf#:~:text=frequent trajectories to ten tactical,results used to visualise meaningful)).
Complexity of real scenarios: Players can change tactics mid-rally. A rally might start defensive and then one player seizes an attack. Recognizing the shift is advanced – it may involve detecting when a player goes from being on the back foot to on the offensive. This could be done by analyzing sequences of shot intents or changes in positioning dominance (who controls the center vs who is forced to lunge more).
Performance Metrics: Evaluating tactical intent recognition depends on how the problem is framed:

If it’s a classification problem (e.g., classify each shot or each rally into categories like Attack/Defense/Neutral), then use precision, recall, F1, and accuracy for those categories. Since one class (neutral) might be more common, a weighted F1 or per-class metrics are useful to see if the model reliably catches the less frequent ones (like correctly identifying when a player is truly in attack mode versus just neutral rallying).
If tactics are identified as patterns (like detecting a “clear-drop combination” tactic), one could measure detection rate of known patterns and the false alarm rate (detecting a tactic when it wasn’t really there).
Another angle is to measure agreement with human experts: have coaches label some rallies for tactics and see how often the algorithm agrees (like a Cohen’s kappa for inter-rater agreement between the model and experts).
If the tactical recognition is used to predict outcomes (e.g., identifying that offensive rallies lead to wins), one can indirectly evaluate by how well these recognized tactics correlate with rally results or player performance statistics.
Related Research: Tactical analysis has been a focus in sports analytics. In badminton, beyond the mentioned trajectory-based classification ([Application of Computer Vision and Vector Space Model for Tactical Movement Classification in Badminton](https://openaccess.thecvf.com/content_cvpr_2017_workshops/w2/papers/Weeratunga_Application_of_Computer_CVPR_2017_paper.pdf#:~:text=frequent trajectories to ten tactical,results used to visualise meaningful)) (Application of Computer Vision and Vector Space Model for Tactical Movement Classification in Badminton), there are visualization tools like TIVEE (Chu et al. 2021) which let analysts explore stroke sequence patterns in 3D, grouping rallies by tactics for a given player ([TIVEE: Visual Exploration and Explanation of Badminton Tactics in Immersive Visualizations](https://ssxiexiao.github.io/papers/TIVEE.pdf#:~:text=Abstract— Tactic analysis is a,In this)) ([TIVEE: Visual Exploration and Explanation of Badminton Tactics in Immersive Visualizations](https://ssxiexiao.github.io/papers/TIVEE.pdf#:~:text=analysis of badminton in a,studies and an expert interview)). TIVEE defines a tactic as a sequence of consecutive strokes and uses clustering on stroke sequences and shuttle trajectories to categorize tactics ([TIVEE: Visual Exploration and Explanation of Badminton Tactics in Immersive Visualizations](https://ssxiexiao.github.io/papers/TIVEE.pdf#:~:text=Abstract

Approach for Automated Tactical Intent Recognition: A plausible modern approach is to use a sequence model (like a Transformer) that takes as input the sequence of strokes (with their types and maybe continuous features like shuttle landing positions) and outputs a parallel sequence of labels for intent or a single label for the sequence’s overall tactic. This could be trained on data labeled by experts. The model could also incorporate features like the rally state (who is in advantage). Some researchers have introduced the concept of a “rally status” or rally balance which tracks which player is controlling the rally – this could be an intermediate variable the model learns (e.g., by an LSTM that outputs a value indicating aggressiveness at each shot). If above a threshold, label as attack, if below, defense.

Improving Generalization: Tactics can vary depending on opponent and context. A model trained on one player’s tactics might not directly apply to another’s style. To generalize:

Use diverse training data including rallies from many different players, both genders (since men’s and women’s singles can have different pace and common tactics), and various play styles.
Include contextual features such as player skill level or known preferences if available, but be cautious not to overfit to them.
Data augmentation isn’t straightforward for sequences, but one can augment by slight variations: e.g., adding noise to positions or randomly dropping a less important shot from the sequence to test robustness.
Validate the model on entirely unseen matches and players, to ensure it’s truly capturing general tactical patterns, not memorizing specific rally scripts.
If possible, incorporate meta-learning or transfer learning where the model learns a general concept of tactics and can adapt to new players with a small amount of data (perhaps learning each player’s style as part of the model, then focusing on the tactic conditional on style).
Outputs and Use: The result of tactical intent recognition could be presented as annotations like: “Shot 5 (a clear) – Defensive (player was off-balance)”, “Shot 6 (opponent’s drop) – Offensive (attempt to finish rally at net)”. Or at a higher level: “Rally #10: Player A employed an attacking clear-and-smash tactic”. Such qualitative labels can be cross-checked with match outcomes (was the tactic successful?). Over many rallies, one can compile statistics: e.g., Player A used offensive tactics in 40% of rallies and won 70% of those, but won only 30% when forced into defensive rallies – a useful insight for match preparation.

In summary, recognizing tactical intent is like adding a layer of interpretation on top of the raw actions. While challenging due to context and nuance, progress can be made by leveraging sequence modeling and expert knowledge. As a hybrid of data-driven patterns and expert-defined categories, this component closes the gap between what happened and why it happened in badminton analysis.

Prediction of Singles Players’ Subsequent Actions
Goal: This component focuses on forecasting what action will happen next in a rally – essentially, rally prediction or next-shot prediction. Given the current state of play (and possibly the history of the rally so far), can we predict what the player (or players) will do next? In badminton, this can mean predicting the next stroke type a player will play, or even the location they will hit to. It can also extend to predicting the eventual outcome of the rally (who will win the point) based on how the rally is unfolding. Anticipating opponent’s shots is a key skill for players; here we attempt to emulate that with AI. This has practical use in strategy simulation (what is the likely response to a certain shot?), enhancing viewer experience (real-time predictions like “85% chance the next shot will be a net shot”), and coaching (identifying if a player’s choices are predictable).

State Representation: To predict the next action, the model must have a representation of the current state of the rally. This state can include:

The sequence of recent strokes (with types, placements).
The positions or motions of the players at the current moment (e.g., player A is back-right corner, player B front-left).
Which player is about to hit (since rallies alternate turns, we should know whose turn it is).
Perhaps the score or stage of match (players might take more risks on crucial points, etc., though this goes into psychology).
Player-specific tendencies (some players favor certain shots in particular situations).
In essence, we treat the rally as a sequence of events and we want to predict the next event. This is analogous to language modeling (predict next word) or sequence prediction in other domains.

Modeling Approaches:

Sequence Models (RNNs/LSTMs): A straightforward approach is to encode the rally sequence using an LSTM or GRU. For example, feed a sequence like [(Shot1 by A), (Shot2 by B), (Shot3 by A)] and have the model output a probability distribution over possible Shot4. Early attempts have been made using recurrent neural networks treating stroke sequences similarly to text ([A Stroke of Genius: Predicting the Next Move in Badminton](https://openaccess.thecvf.com/content/CVPR2024W/CVsports/papers/Ibh_A_Stroke_of_Genius_Predicting_the_Next_Move_in_Badminton_CVPRW_2024_paper.pdf#:~:text=strategic shuttle placement%2C presents a,Datastructure overview)) ([A Stroke of Genius: Predicting the Next Move in Badminton](https://openaccess.thecvf.com/content/CVPR2024W/CVsports/papers/Ibh_A_Stroke_of_Genius_Predicting_the_Next_Move_in_Badminton_CVPRW_2024_paper.pdf#:~:text=factors into the prediction process,14)). One can train such a model on a large number of rallies.
Transformer-based Sequence-to-Sequence: Modern approaches, as cited in recent research, use Transformers for this prediction task. A paper by Ibh et al. (2024) introduced RallyTemPose, a transformer encoder-decoder model for stroke forecasting ([A Stroke of Genius: Predicting the Next Move in Badminton](https://openaccess.thecvf.com/content/CVPR2024W/CVsports/papers/Ibh_A_Stroke_of_Genius_Predicting_the_Next_Move_in_Badminton_CVPRW_2024_paper.pdf#:~:text=This paper presents%2C RallyTemPose%2C a,RallyTemPose shows improved)). Their model encodes spatiotemporal info (including player skeleton and positions) and uses a decoder to predict subsequent strokes, conditioning on the encoded history ([A Stroke of Genius: Predicting the Next Move in Badminton](https://openaccess.thecvf.com/content/CVPR2024W/CVsports/papers/Ibh_A_Stroke_of_Genius_Predicting_the_Next_Move_in_Badminton_CVPRW_2024_paper.pdf#:~:text=This
Contextual Features: Including more than just the sequence of stroke labels greatly improves prediction ([A Stroke of Genius: Predicting the Next Move in Badminton](https://openaccess.thecvf.com/content/CVPR2024W/CVsports/papers/Ibh_A_Stroke_of_Genius_Predicting_the_Next_Move_in_Badminton_CVPRW_2024_paper.pdf#:~:text=subsequent stroke predictions involves incorporating,contain the motion of player)) ([A Stroke of Genius: Predicting the Next Move in Badminton](https://openaccess.thecvf.com/content/CVPR2024W/CVsports/papers/Ibh_A_Stroke_of_Genius_Predicting_the_Next_Move_in_Badminton_CVPRW_2024_paper.pdf#:~:text=limitations,based rally awareness)). RallyTemPose incorporates:
Skeleton pose sequences: the joints movement of the player about to hit, which provides cues about what stroke they are preparing (e.g., certain jump posture telegraphs a smash) ([A Stroke of Genius: Predicting the Next Move in Badminton](https://openaccess.thecvf.com/content/CVPR2024W/CVsports/papers/Ibh_A_Stroke_of_Genius_Predicting_the_Next_Move_in_Badminton_CVPRW_2024_paper.pdf#:~:text=model,give information about future strokes)).
Court position of the shuttle and players: where the shuttle is and where the players are positioned influences choice (a player at the back line might likely play a drop if the opponent is far).
Player identity and style embeddings: Each player can be associated with a profile or embedding that captures their personal style (some might prefer smashes, some play more clears). Including player ID allows the model to adjust predictions to that player’s known habits ([A Stroke of Genius: Predicting the Next Move in Badminton](https://openaccess.thecvf.com/content/CVPR2024W/CVsports/papers/Ibh_A_Stroke_of_Genius_Predicting_the_Next_Move_in_Badminton_CVPRW_2024_paper.pdf#:~:text=limitations,based rally awareness)). For example, if Lin Dan is known for his net kill after a smash, the model can predict that as a likely sequence when he’s involved.
Turn indicator: specifying which player is hitting helps the model separate the roles (since the same sequence of shots means different things if we flip players).
Next Action vs Multi-step Prediction: One can train the model to predict just the next stroke, or to output the probabilities of the next N strokes (a multi-step forecast). Typically, next-shot prediction is done iteratively (predict one, then incorporate it and predict next). Some research, like ShuttleNet (Wang et al. 2022), used a sequence-to-sequence approach to forecast an entire remaining rally as a sequence of strokes ([[2112.01044] ShuttleNet: Position-aware Fusion of Rally Progress ...](https://arxiv.org/abs/2112.01044#:~:text=... arxiv.org ShuttleNet%3A Position,Han Shuai%2C)) ([GitHub - wywyWang/ShuttleNet](https://github.com/wywyWang/ShuttleNet#:~:text=GitHub ,AAAI'22))). They introduced a position-aware and player-style aware LSTM network that could predict not only the type of next stroke but also the landing position, integrating “rally progress” as a feature (meaning the stage of the rally) ([[2112.01044] ShuttleNet: Position-aware Fusion of Rally Progress ...](https://arxiv.org/abs/2112.01044#:~:text=...
Hybrid Analytical Methods: In some cases, simpler predictive models like Markov chains have been applied. One can estimate transition probabilities: e.g., from state (player at back, plays clear) the next state distribution could be X% opponent smashes, Y% opponent drops, etc., derived from data. While not as flexible as deep learning, Markov models provide insight into the rally dynamics and can serve as a baseline. More advanced, there are studies combining physical models (for shuttle trajectory) with prediction: e.g., if a smash is predicted, one might simulate the likely shuttle path to where the opponent will move.
Reinforcement Learning perspective: Though not exactly prediction, one can imagine training an RL agent to play badminton; the learned policy could implicitly give probabilities of actions in given states. Some work has not reached that stage due to complexity, but conceptually it’s related.
Performance Metrics:

Accuracy of prediction: Typically measured as top-1 accuracy of the predicted stroke type compared to what actually happened. For example, if the model predicted “smash” as the most likely next shot and a smash indeed occurred, that’s a hit. Given the uncertainty in sports, top-1 accuracy might not be very high (since players have multiple choices); thus Top-k accuracy is also reported (did the actual next shot appear in the model’s top 2 or 3 predictions?). A model like RallyTemPose showed improved forecasting accuracy over simpler methods ([A Stroke of Genius: Predicting the Next Move in Badminton](https://openaccess.thecvf.com/content/CVPR2024W/CVsports/papers/Ibh_A_Stroke_of_Genius_Predicting_the_Next_Move_in_Badminton_CVPRW_2024_paper.pdf#:~:text=in a decoder module through,the latent representations learned by)) – although exact numbers vary by dataset, an example from literature: an LSTM might get around 40-50% next-shot accuracy on a moderately sized set, whereas adding context and transformer architecture could push that higher (some research shows 60-70% top-1 for next stroke when including rich features ([A Stroke of Genius: Predicting the Next Move in Badminton](https://openaccess.thecvf.com/content/CVPR2024W/CVsports/papers/Ibh_A_Stroke_of_Genius_Predicting_the_Next_Move_in_Badminton_CVPRW_2024_paper.pdf#::text=This paper presents%2C RallyTemPose%2C a,RallyTemPose shows improved)) ([A Stroke of Genius: Predicting the Next Move in Badminton](https://openaccess.thecvf.com/content/CVPR2024W/CVsports/papers/Ibh_A_Stroke_of_Genius_Predicting_the_Next_Move_in_Badminton_CVPRW_2024_paper.pdf#:~:text=in
Cross-entropy or log-likelihood: Since this is often a probabilistic prediction, the quality can be measured by how well the model’s probability distribution matches the actual distribution of outcomes (lower cross-entropy is better). This is useful during training and evaluation, beyond just accuracy.
Outcome prediction accuracy: If the goal is to predict who wins the rally, that can be a separate evaluation. Some works focus on rally outcome prediction, achieving decent accuracy by looking at sequences of shots (treating it as a sequence classification where classes are “win” or “lose” for the player of interest) ([A deep learning based framework for badminton rally outcome ...](https://ieeexplore.ieee.org/document/10082764/#:~:text=,rally outcome in badminton games)).
Timeliness: For a real-time system, can the prediction be made before the opponent hits the shot? That requires low-latency processing and possibly anticipating as soon as the last shot is launched. This might be more of a system evaluation: e.g., measuring how many milliseconds before the actual shot the prediction is available.
Related Work: The idea of predicting the next move is gaining traction across sports:

In badminton, aside from RallyTemPose ([A Stroke of Genius: Predicting the Next Move in Badminton](https://openaccess.thecvf.com/content/CVPR2024W/CVsports/papers/Ibh_A_Stroke_of_Genius_Predicting_the_Next_Move_in_Badminton_CVPRW_2024_paper.pdf#:~:text=This paper presents%2C RallyTemPose%2C a,RallyTemPose shows improved)), ShuttleNet ([[2112.01044] ShuttleNet: Position-aware Fusion of Rally Progress ...](https://arxiv.org/abs/2112.01044#:~:text=... arxiv.org ShuttleNet%3A Position,Han Shuai%2C)), there’s work on using attention to identify important strokes for determining rally outcome ([Exploring the Long Short-Term Dependencies to Infer Shot Influence ...](https://ieeexplore.ieee.org/document/9679184/#:~:text=Exploring the Long Short,essential for badminton experts)) (Chan et al. 2019) – not exactly next shot, but who wins given sequence (the model implicitly learns which shot types lead to wins). Another approach (Yu et al.) looked at stroke influence: how each shot contributes to winning chances ([Exploring the Long Short-Term Dependencies to Infer Shot Influence ...](https://ieeexplore.ieee.org/document/9679184/#:~:text=Exploring
In tennis, researchers have predicted next shot placement (down the line vs crosscourt, etc.) using player positioning and match context.
In table tennis, high-speed cameras and sensors have been used to predict opponent’s strokes for assistive robots.
The cited RallyTemPose also did an interesting thing: they used a pre-trained language model to embed stroke descriptions ([A Stroke of Genius: Predicting the Next Move in Badminton](https://openaccess.thecvf.com/content/CVPR2024W/CVsports/papers/Ibh_A_Stroke_of_Genius_Predicting_the_Next_Move_in_Badminton_CVPRW_2024_paper.pdf#:~:text=considerations to make more informed,The code can)). This is an innovative approach where text descriptions of strokes were used to create a richer representation of stroke types (almost like “semantic” embedding of actions). This improved generalization by informing the model of similarities/differences between strokes in a descriptive way.
ShuttleNet’s inclusion of “player styles” ([[2112.01044] ShuttleNet: Position-aware Fusion of Rally Progress ...](https://arxiv.org/abs/2112.01044#:~:text=... arxiv.org ShuttleNet%3A Position,Han Shuai%2C)) indicates modeling long-term patterns (some players consistently favor certain patterns).
Practical Considerations and Best Practices:

Train in a player-agnostic way but allow personalization: A model should generalize to new players (so it doesn’t completely rely on, say, recognizing Lin Dan specifically). One way is “player-independent” training – e.g., leave one player’s matches out for testing as in some research ([A deep learning based framework for badminton rally outcome ...](https://ieeexplore.ieee.org/document/10082764/#:~:text=,rally outcome in badminton games)). But when deploying, if you know the players, you can feed their identity to the model (as done by RallyTemPose) to bias predictions toward their habits ([A Stroke of Genius: Predicting the Next Move in Badminton](https://openaccess.thecvf.com/content/CVPR2024W/CVsports/papers/Ibh_A_Stroke_of_Genius_Predicting_the_Next_Move_in_Badminton_CVPRW_2024_paper.pdf#:~:text=limitations,based rally awareness)). This combination yields general patterns with personal tweaks.
Incorporate uncertainty: Even the best model will have uncertainty due to the inherent stochastic nature of sport. Instead of only a single prediction, providing a probability distribution or a few likely options can be more useful. For instance, “model predicts 50% chance of clear, 30% chance of drop, 20% of smash”. If using this in coaching, one might prepare the player primarily for the clear but also be ready for the drop.
Use of real-time data: If this is used live, one must get the input features quickly – e.g., using the tracking data from component 1 (player positions, shuttle trajectory) and the recognized stroke from component 2 for the last shot. Then the model can output prediction for the next. Low latency computing (possibly on the edge or a fast cloud) is needed to beat the shuttle speed – a shuttle can go from one side to the other in under a second. If the system responds in say 100ms after the opponent hits, that could be enough for an on-court assistive device to alert a player (though realistically, such a device is more theoretical due to fairness rules).
Continuous learning: As players adapt during a match, a static model might not capture a sudden change in tactics. An advanced system might do online learning, updating predictions if it notices, for example, that a player has unexpectedly started using drop shots more than their usual pattern. However, caution is needed to avoid reacting to just noise.
Evaluation and Generalization: To ensure the prediction model generalizes:

Test it on completely new tournaments or player sets. If possible, test on lower-level matches if trained on pro matches, to see if it still works when the style of play changes (amateur rallies might have more clears and fewer smashes, for instance).
Evaluate robustness: if the input tracking has some errors, does the prediction drop drastically or is it tolerant? It should handle slightly noisy positions or occasional mis-identified strokes gracefully.
Incorporate different match conditions: singles vs doubles are different (our focus is singles, but within singles, men’s vs women’s singles pace differs; also sometimes indoor vs outdoor). Ideally, the model trained on one context (e.g., men’s singles) can adapt to another with minimal retraining.
Performance-wise, current research models like the transformer-based RallyTemPose have shown improvement over baselines like LSTMs ([A Stroke of Genius: Predicting the Next Move in Badminton](https://openaccess.thecvf.com/content/CVPR2024W/CVsports/papers/Ibh_A_Stroke_of_Genius_Predicting_the_Next_Move_in_Badminton_CVPRW_2024_paper.pdf#:~:text=in a decoder module through,the latent representations learned by)). The inclusion of rich context (pose, player info) is credited with that performance boost ([A Stroke of Genius: Predicting the Next Move in Badminton](https://openaccess.thecvf.com/content/CVPR2024W/CVsports/papers/Ibh_A_Stroke_of_Genius_Predicting_the_Next_Move_in_Badminton_CVPRW_2024_paper.pdf#:~:text=in

Closing Thoughts on Prediction: Successfully predicting the next action not only has practical value but also validates the earlier components: if our models for detection, classification, and context are good, the prediction is the synthesis that uses all of them. A high-performing prediction model essentially means our system “understands” the game to a certain extent. While no model will predict 100% (players can always do the unexpected), even 60-70% accuracy can be very useful over many rallies. Importantly, these predictions can feed back into tactical analysis: if a model consistently predicts a particular shot in a situation, that suggests players often do that – which could be a tactical insight. Conversely, if a player deviates from what the model (trained on generic data) would predict, that player might have a unique style worth noting.

Conclusion and General Recommendations
Analyzing singles badminton actions from video involves a pipeline of tasks: detecting and tracking the objects of interest, identifying what actions are executed, interpreting why they are executed, and forecasting what will happen next. Each component builds on the previous, and optimizing each is crucial for a reliable end-to-end system.

Performance Metrics & Evaluation: Across all components, it’s important to use the right metrics and evaluation methodologies:

Use domain-specific metrics where needed (e.g., rally-based metrics for tactics, top-k accuracy for prediction, etc.) and not just generic accuracy, to get a full picture of performance.
Perform error analysis: Examine cases where the system’s predictions or recognitions differ from ground truth. Are there common themes (e.g., shuttle tracking fails in very low light videos, or tactical intent misclassified when players are of vastly different skill)? This helps target improvements.
Evaluate generalization by splitting data smartly: e.g., train on some tournaments, test on a different tournament; ensure that when evaluating stroke recognition, the players in test set were not seen in training, to simulate application to new players ([A deep learning based framework for badminton rally outcome ...](https://ieeexplore.ieee.org/document/10082764/#:~:text=,rally outcome in badminton games)).
Consider real-time evaluation: if the application is real-time, measure the end-to-end latency from video frame to output (including all processing stages). If it’s too slow, consider model compression or hardware acceleration.
Dataset Curation and Annotation: This project would benefit from a well-curated dataset that ties together all components. Ideally, a dataset of annotated badminton singles rallies where:

Every frame (or at least key frames per shot) has the shuttlecock position and players’ bounding boxes (for tracking ground truth).
Every shot is segmented and labeled with its stroke type (technical action).
Tactical intent labels are provided either per shot (attack/defend) or per rally (who was dominating, what strategy was used).
The sequences of shots are recorded for use in prediction models.
To build such a dataset, one could start with a few full match videos and manually annotate them with the help of badminton experts. Tools can be developed to semi-automatically annotate (e.g., a tool that lets annotators mark the shot types on a timeline while watching the video, possibly pre-filled by a rough model to speed up labeling). Consistency in annotation is key: provide clear definitions (perhaps a handbook for annotators). Using multiple annotators and measuring inter-rater reliability for subjective labels like tactics is advised – if it’s low, refine the definitions.

Generalization Strategies: Badminton matches can differ widely in camera viewpoint (e.g., some training videos might be taken from the side of the court, whereas broadcast is usually from an elevated back-court angle). To generalize across scenarios:

Use data augmentation extensively: simulate different camera angles by rotating or scaling the court in the image, use GANs or style transfer to vary background, etc.
Use domain adaptation techniques: e.g., if training on broadcast footage and deploying on a fixed camera in a gym, one could fine-tune the detection model on a small set of images from the gym (to adapt to different lighting or court colors).
Ensure robust features: For example, pose-based features generalize to clothing changes or lighting better than raw pixel features. Combining both gives resilience.
Ensemble methods: Sometimes combining models (one trained on one set of conditions, another on different conditions) and letting them vote or switch based on scenario can help. For instance, one tracking model might be specialized for low-res footage, another for high-res; the system could choose appropriate one based on input resolution.
Continuous learning: as more data is collected (e.g., the system is used by many coaches, and those coaches correct its errors), feed those corrections back into retraining to progressively improve the model. This requires an infrastructure for data collection and privacy considerations if needed.
Integration of Components: Finally, while we optimized each component separately, in practice an integrated system should be tested end-to-end. For example, errors in object tracking (component 1) will propagate to stroke recognition (component 2) if the model misses a shuttle, it might also miss registering a stroke. Designing the system to handle such failures gracefully is important – e.g., if shuttle tracking fails on a rally, perhaps default to using player movement cues for that rally’s analysis, or have a fallback generic model for strokes using just player swing. Similarly, the tactical intent recognition can be made robust to occasional misclassified strokes by focusing on patterns, not single-shot labels.

Comparison with Human Performance: It’s interesting to note that humans (even professional analysts) might only qualitatively analyze a few aspects during a match, whereas an AI can quantitatively track every detail. The aim is not to replace human insight but to augment it with comprehensive data. The success of such a system would be measured by how well it can assist in real-world applications: Do coaches find the automatically generated analysis useful? Does it correlate with their own assessments? Does it perhaps uncover non-obvious patterns (e.g., “when under pressure, this player’s defensive clears tend to be short, leading to smashes by opponent”)? Those kinds of findings show the power of combining these four components.

In conclusion, the project of analyzing singles badminton player actions via video requires a synergy of computer vision, deep learning, and domain knowledge of badminton. By detecting and tracking with high precision, classifying technical actions with fine detail, interpreting tactics with contextual intelligence, and predicting future moves, we move towards a comprehensive “AI badminton analyst.” The recommended approaches – from using YOLO and TrackNet for object tracking to Transformers and Graph Convolutional Networks for action recognition – represent the state-of-the-art in each area. Adhering to best practices in dataset creation, model training, and evaluation will ensure the system is robust and generalizes across different matches and scenarios. With continued refinement (and possibly more data from sources like sensors or multiple cameras), such a system could greatly benefit coaches, players, and fans by providing deeper insights into the beautiful, rapid game of badminton ([Enhancing Badminton Game Analysis: An Approach to Shot Refinement via a Fusion of Shuttlecock Tracking and Hit Detection from Monocular Camera](https://www.mdpi.com/1424-8220/24/13/4372#:~:text=model is used to identify,1)) ([A Stroke of Genius: Predicting the Next Move in Badminton](https://openaccess.thecvf.com/content/CVPR2024W/CVsports/papers/Ibh_A_Stroke_of_Genius_Predicting_the_Next_Move_in_Badminton_CVPRW_2024_paper.pdf#:~:text=This paper presents%2C RallyTemPose%2C a,RallyTemPose shows improved)).